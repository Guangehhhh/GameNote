## RTR
---
## 基于物理着色（Physically Based Shading）
- 就是计算机图形学中用数学建模的方式，模拟物体表面各种材质散射光线的属性
  - 从而渲染照片真实图片的技术
## 图形渲染管线
# 架构
  - 应用，几何，光栅化
  - 最慢的管线阶段决定绘制速度
# 应用阶段
  - 通过软件方式来实现的阶段
  - 用户可完全掌控，运行在CPU
  - 可以在几个并行处理器上同时执行
  - 应用程序阶段虽然是一个单独的过程，但是依然可以对之进行管线化或者并行化处理
  - 有碰撞检测、加速算法、输入检测，动画，力反馈以及纹理动画，变换仿真、几何变形   
    - 以及一些不在其他阶段执行的计算，如层次视锥裁剪等加速算法就可以在这里实现
      - 对应虚幻的 InitView 可见性判断
  - 阶段的末端，将需要在屏幕上（具体形式取决于具体输入设备）显示出来绘制的几何体
    - 也就是绘制图元，rendering  primitives，如点、线、矩形等 输入到绘制管线的下一个阶段
  - 对于被渲染的每一帧，应用程序阶段将摄像机位置，光照和模型的图元输出到管线的下一个主要阶段——几何阶段。
# 几何阶段
  - 一些情况下，一系列连续的功能阶段可以形成单个管线阶段（和其他管线阶段并行运行）
    - 在另外情况下，一个功能阶段可以划分成其他更细小的管线阶段
  - 几何阶段执行的是计算量非常高的任务，在只有一个光源的情况下
    - 每个顶点大约需要100次左右的精确的浮点运算操作
  - 模型变换 视图变换
    - 模型变换的目的是将模型变换到适合渲染的空间当中
    - 视图变换的目的是将摄像机放置于坐标原点，方便后续步骤的操作
    - 在屏幕上的显示过程中，模型通常需要变换到若干不同的空间或坐标系中
      - 模型变换的变换对象一般是模型的顶点和法线
      - 物体的坐标称为模型坐标
      - 世界空间是唯一的，所有的模型经过变换后都位于同一个空间中
    - 不难理解，应该仅对相机（或者视点）可以看到的模型进行绘制
      - 相机在世界空间中有一个位置方向，用来放置和校准相机
    - 为了便于投影和裁剪，必须对相机和所有的模型进行视点变换
      - 变换的目的就是要把相机放在原点，然后进行视点校准
        - 使其朝向Z轴负方向，y轴指向上方,x轴指向右边
        - 在视点变换后，实际位置和方向就依赖于当前的API
        - 称上述空间为相机空间或者观察空间
  - 顶点着色
    - 为了产生逼真的场景，渲染形状和位置是远远不够的，我们需要对物体的外观进行建模
    - 物体经过建模，会得到对每个对象的材质
      - 照射在对象上的任何光源的效果在内的一些描述
      - 且光照和材质可以用任意数量的方式，从简单的颜色描述到复杂的物理描述来模拟
    - 确定材质上的光照效果的这种操作被称为着色（shading）
      - 着色过程涉及在对象上的各个点处计算着色方程（shadingequation）
    - 这些计算中的一些在几何阶段期间在模型的顶点上执行（vertexshading）
    - 其他计算可以在每像素光栅化（per-pixelrasterization）期间执行
    - 也可以在每个顶点处存储各种材料数据，诸如点的位置，法线，颜色或计算着色方程所需的任何其它数字信息
    - 顶点着色的结果（其可以是颜色，向量，纹理坐标或任何其他种类的阴着色数据）计算完成后，会被发送到光栅化阶段以进行插值操作

    - 着色计算通常认为是在世界空间中进行的
    - 有时需要将相关实体（诸如相机和光源）转换到一些其它空间（诸如模型或观察空间）并在那里执行计算
    - 这是因为如果着色过程中所有的实体变换到了相同的空间
      - 着色计算中需要的诸如光源，相机和模型之间的相对关系是不会变的。
    - 顶点着色阶段的目的在于确定模型上顶点处材质的光照效果
  - 投影变换
    - 在光照处理之后，就开始进行投影操作
      - 即将视体变换到一个对角顶点分别是(-1,-1,-1)和(1,1,1)单位立方体（unitcube）内
      - 这个单位立方体通常也被称为规范立方体（Canonical View Volume，CVV）

    - 目前，主要有两种投影方法，即：
    - 正交投影
      - 可视体通常是一个矩形，正交投影可以把这个视体变换为单位立方体
      - 正交投影的主要特性是平行线在变换之后彼此之间仍然保持平行，这种变换是平移与缩放的组合
    - 透视投影
      - 透视投影比正交投影复杂一些。在这种投影中，越远离摄像机的物体，它在投影后看起来越小。
      - 更进一步来说，平行线将在地平线处会聚。透视投影的变换其实就是模拟人类感知物体的方式。

    - 正交投影和透视投影都可以通过4x4的矩阵来实现
      - 在任何一种变换之后，都可以认为模型位于归一化处理之后的设备坐标系中

    - 虽然这些矩阵变换是从一个可视体变换到另一个，但它们仍被称为投影
      - 因为在完成显示后，Z坐标将不会再保存于的得到的投影图片中
    - 通过这样的投影方法，就将模型从三维空间投影到了二维的空间中

  - 裁剪
    - 裁剪阶段的目的，就是对部分位于视体内部的图元进行裁剪操作
    - 只有当图元完全或部分存在于视体（也就是上文的规范立方体，CVV）内部的时候，
      - 才需要将其发送到光栅化阶段，这个阶段可以把这些图元在屏幕上绘制出来。

    - 一个图元相对视体内部的位置，分为三种情况：完全位于内部、完全位于外部、部分位于内部
      - 所以就要分情况进行处理：
        -   当图元完全位于视体内部，那么它可以直接进行下一个阶段。
        -   当图元完全位于视体外部，不会进入下一个阶段，可直接丢弃，因为它们无需进行渲染。
        -   当图元部分位于视体内部，则需要对那些部分位于视体内的图元进行裁剪处理
  - 屏幕映射
    - 只有在视体内部经过裁剪的图元，才可以进入到屏幕映射阶段
      - 进入到这个阶段时，坐标仍然是三维的（但显示状态在经过投影阶段后已经成了二维）
      - 每个图元的x和y坐标变换到了屏幕坐标系中，屏幕坐标系连同z坐标一起称为窗口坐标系

    - 假定在一个窗口里对场景进行绘制，窗口的最小坐标为（x1，y1），最大坐标为（x2，y2），其中x1\<x2，y1\<y2。屏幕映射首先进行平移，随后进行缩放，在映射过程中z坐标不受影响。新的x和y坐标称为屏幕坐标系，与z坐标一起（-1≦
    z ≦ 1）进入光栅化阶段。

    - 经过投影变换，图元全部位于单位立方体之内，而屏幕映射主要目的就是找到屏幕上对应的坐标

    - 屏幕映射阶段的一个常见困惑是整型和浮点型的点值如何与像素坐标（或纹理坐标）进行关联。可以使用Heckbert[书后参考文献第520篇]的策略，用一个转换公式进行解决

    - 屏幕映射阶段的主要目的，就是将之前步骤得到的坐标映射到对应的屏幕坐标系上。
# 光栅化
  - 用经过变换和投影之后的顶点，颜色以及纹理坐标（均来自于几何阶段）给每个像素（Pixel）正确配色，正确绘制整幅图像
    - 这个过个过程叫光珊化（rasterization）或扫描变换（scanconversion）
    - 即从二维顶点所处的屏幕空间（所有顶点都包含Z值即深度值，及各种与相关的着色信息）到屏幕上的像素的转换
  - 三角形Setup
    - 三角形设定阶段主要用来计算三角形表面的差异和三角形表面的其他相关数据
    - 该数据主要用于扫描转换scanconversion，以及由几何阶段处理的各种着色数据的插值操作所用
    - 该过程在专门为其设计的硬件上执行
  - 三角形遍历
    - 逐像素检查操作，检查该像素处的像素中心是否由三角形覆盖
      - 而对于有三角形部分重合的像素，将在其重合部分生成片段（fragment）
    - 找到采样点或像素在三角形中的过程通常叫三角形遍历TriangleTraversal或扫描转换
    - 每个三角形片段的属性均由三个三角形顶点的数据插值而生成
      - 这些属性包括片段的深度，以及来自几何阶段的着色数据

  - 像素着色
    - 所有逐像素的着色计算都在像素着色阶段进行，使用插值得来的着色数据作为输入
    - 输出结果为一种或多种将被传送到下一阶段的颜色信息
    - 纹理贴图操作就是在这阶段进行的

    - 像素着色阶段是在可编程GPU内执行的，在这一阶段有大量的技术可以使用
    - 其中最常见，最重要的技术之一就是纹理贴图（Texturing）
      - 纹理贴图就是将指定图片“贴”到指定物体上的过程
      - 而指定的图片可以是一维，二维，或者三维的，其中，自然是二维图片最为常见
    - 像素着色阶段的主要目的是计算所有需逐像素操作的过程
  - 融合
    - 主要任务是合成当前储存于缓冲器中像素着色阶段产生的片段颜色
    - 每个像素的信息都储存在颜色缓冲器中，而颜色缓冲器是一个颜色的矩阵
      - 每种颜色包含红、绿、蓝三个分量
    - 运行该阶段的GPU子单元并非完全可编程的，但其高度可配置，可支持多种特效

    - 这个阶段还负责可见性问题的处理
      - 当绘制完整场景的时候，颜色缓冲器还包含从相机视点处可以观察到的场景图元
      - 大多数图形硬件是通过Z缓冲（也称深度缓冲器）算法来实现的
        - Z缓冲算法非常简单，具有O(n)复杂度（n是需要绘制的像素数量）
          - 只要对每个图元计算出相应的像素z值，就可以使用这种方法，大概内容是：

          - Z缓冲器器和颜色缓冲器形状大小一样，每个像素都存储着一个z值，这个z值是从相机到最近图元之间的距离
          - 每次将一个图元绘制为相应像素时，需要计算像素位置处图元的z值，并与同一像素处的z缓冲器内容进行比较
          - 如果新计算出的z值，远远小于z缓冲器中的z值，那么说明即将绘制的图元与相机的距离比原来距离相机最近的图元还要近
          - 这样，像素的z值和颜色就由当前图元对应的值和颜色进行更新
          - 反之，若计算出的z值远远大于z缓冲器中的z值，那么z缓冲器和颜色缓冲器中的值就无需改变

    - 颜色缓冲器用来存储颜色，z缓冲器用来存储每个像素的z值
    - 还有其他缓冲器可以用来过滤和捕获片段信息
      - 比如alpha通道（alphachannel）和颜色缓冲器联系在一起可以存储一个与每个像素相关的不透明值
        - 可选alpha测试可在，深度测试执行前在传入片段上运行
        - 片段的alpha值与参考值作某些特定的测试（如等于，大于等）
          - 如果片断未能通过测试，它将不再进行进一步的处理
        - alpha测试经常用于，不影响深度缓存的全透明片段的处理
      - 模板缓冲器（stencilbuffer）是用于记录所呈现图元位置的离屏缓存
        - 每个像素通常与占用8个位 unit8
        - 图元可使用各种方法渲染到模板缓冲器中，而缓冲器中的内容可以控制颜色缓存和Z缓存的渲染
          - 举个例子，假设在模版缓冲器中绘制出了一个实心圆形
            - 那么可以使用一系列操作符来将后续的图元仅在圆形所出现的像素处绘制，类似一个mask的操作
          - 模板缓冲器是制作特效的强大工具
            - 而在管线末端的所有这些功能都叫做光栅操作（ROP）或混合操作（blend operations）
      - 帧缓冲器（framebuffer）通常包含一个系统所具有的所有缓冲器
        - 但有时也可以认为是颜色缓冲器和z缓冲器的组合
      - 累计缓冲器（accumulationbuffer），是1990年，Haeberli和Akeley提出的一种缓冲器
        - 是对帧缓冲器的补充。这个缓冲器可以用一组操作符对图像进行累积
        - 例如，为了产生运动模糊（motionblur.，可以对一系列物体运动的图像进行累积和平均
          - 此外，其他的一些可产生的效果包括景深depth of field，反走样antialiasing和软阴影

    - 当图元通过光栅化阶段之后，从相机视点处看到的东西就可以在荧幕上显示出来
      - 为了避免观察者体验到对图元进行处理并发送到屏幕的过程图形系统一般使用了双缓冲doublebuffering   
        - 这意味着屏幕绘制是在一个后置缓冲器（backbuffer）中以离屏的方式进行的
        - 一旦屏幕已在后置缓冲器中绘制，后置缓冲器中的内容就不断与已经在屏幕上显示过的前置缓冲器中的内容进行交换，只有当不影响显示的时候，才进行交换 SwapChain
---
## GPU渲染管线与可编程着色器
# GPU管线 概述
  - 第一个包含顶点处理，面向消费者的图形芯片（NVIDIA GeForce256）发布于1999年
    - 且NVIDIA提出了图形处理单元（Graphics Processing Unit，GPU）这一术语
      - 将GeForce256和之前的只能进行光栅化处理的图形芯片相区分。
      - 在接下来的几年中，GPU从可配置的固定功能管线演变到了支持高度可编程的管线。
      - 直到如今，各种可编程着色器依然是控制GPU的主要手段。
      - 为了提高效率，GPU管线的一部分仍然保持着可配置
        - 但不是可编程的，但大趋势依然是朝着可编程和更具灵活性的方向在发展。

  - GPU实现了第二章中描述的几何和光栅化概念管线阶段
    - 其被分为一些不同程度的可配置性和可编程性的硬件阶段

  - GPU实现的渲染管线和第二章中描述的渲染管线的功能阶段在结构上略有不同

  -  顶点着色器（The Vertex Shader）是完全可编程的阶段
    - 顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作，提供了修改/创建/忽略顶点相关属性的功能，这些顶点属性包括颜色、法线、纹理坐标和位置。顶点着色器的必须完成的任务是将顶点从模型空间转换到齐次裁剪空间。

  -  几何着色器（The Geometry Shader）位于顶点着色器之后，允许GPU高效地创建和销毁几何图元
    - 几何着色器是可选的，完全可编程的阶段，主要对图元（点、线、三角形）的顶点进行操作。
    - 几何着色器接收顶点着色器的输出作为输入，通过高效的几何运算，将数据输出，数据随后经过几何阶段和光栅化阶段的其他处理后，会发送给片段着色器

  -  像素着色器（Pixel Shader，Direct3D中的叫法）常常又称为片断着色器，片元着色器Fragment Shader是完全可编程的阶段，主要作用是进行像素的处理，让复杂的着色方程在每一个像素上执行。
  -  裁剪（Clipping）属于可配置的功能阶段，在此阶段可选运行的裁剪方式，以及添加自定义的裁剪面。
  -  屏幕映射（Screen Mapping）、三角形设置（Triangle Setup）和三角形遍历（Triangle Traversal）阶段是固定功能阶段
  -  合并阶段（The Merger Stage）处于完全可编程和固定功能之间，尽管不能编程，但是高度可配置
    - 其除了进行合并操作，还分管颜色修改（Color Modifying），Z缓冲（Z-buffer），混合（Blend），模板（Stencil）和相关缓存的处理

  - GPU管线已经远离硬编码的运算操作，而朝着提高灵活性和控制性改进
# 可编程着色模型
  - 现代着色阶段（比如支持shader model 4.0，DirectX 10以及之后）使用了通用着色核心（common-shader core），这就表明顶点，片段，几何着色器共享一套编程模型
  - 早期的着色模型可以用汇编语言直接编程，但DX10之后，汇编就只在调试输出阶段可见，改用高级着色语言
  - 目前的着色语言都是C-like的着色语言，比如HLSL,CG和GLSL，其被编译成独立于机器的汇编语言，也称为中间语言（IL）。
    - 这些汇编语言在单独的阶段，通常是在驱动中，被转化成实际的机器语言
    - 这样的安排可以兼容不同的硬件实现。
    - 这些汇编语言可以被看做是定义一个作为着色语言编译器的虚拟机
      - 这个虚拟机是一个处理多种类型寄存器和数据源、预编了一系列指令的处理器
  - 着色语言虚拟机可以理解为一个处理多种类型寄存器和数据源、预编了一系列指令的处理器
    - 考虑到很多图形操作都使用短矢量（最高四位），处理器拥有4路SIMD（single-instruction multiple-data，单指令多数据）兼容性
    - 每个寄存器包含四个独立的值。32位单精度浮点的标量和矢量是其基本数据类型；也随后支持32位整型。
    - 浮点矢量通常包含数据如位置（xyzw），法线，矩阵行，颜色（rgba），或者纹理坐标（uvwq）
    - 而整型通常用来表示，计数器，索引，或者位掩码。也支持综合数据类型比如结构体，数组，和矩阵
    - 而为了便于使用向量，向量操作如调和（swizzling，也就是向量分量的重新排序或复制），和屏蔽（masking，只使用指定的矢量元素），也能够支持


    - 图3.2 DX 10下的通用Shader核心虚拟机架构以及寄存器布局。每个资源旁边显示最大可用编号。其中，用两个斜杠分开的三个数值，分别是顶点，几何、像素着色器对应的可用最大值。

  - 一个绘制调用（Draw Call）会调用图形API来绘制一系列的图元
    - 会驱使图形管线的运行
  - 每个可编程着色阶段拥有两种类型的输入：
    - uniform输入，在一个draw call中保持不变的值（但在不同draw call之间可以更改）
    - varying输入，shader里对每个顶点和像素的处理都不同的值
      - 纹理是特殊类型的uniform输入，曾经一直是一张应用到表面的彩色图片
        - 但现在可以认为是存储着大量数据的数组。

  - 在现代GPU上 ，图形运算中常见的运算操作执行速度非常快。
    - 通常情况下，最快的操作是标量和向量的乘法和加法，以及他们的组合
      - 如乘加运算（multiply-add）和点乘 （dot-product）运算
      - 其他操作，比如倒数（reciprocal）, 平方根（square root），正弦（sine），余弦（cosine），指数（exponentiation）、对数（logarithm）运算，往往会稍微更加昂贵，但依然相当快捷
      - 纹理操作非常高效，但他们的性能可能受到诸如等待检索结果的时间等因素的限制
  - 着色语言表示出了大多数场常见的操作（比如加法和乘法通过运算符+和\*来表示）
    - 其余的操作用固有的函数，比如atan() , dot() , log(),等
    - 更复杂的操作也存在内建函数，比如矢量归一化（vector normalization）、反射（reflection）、叉乘（cross products）、矩阵的转置（matrix transpose）和行列式（determinant）等

  - 流控制（flow control）是指使用分支指令来改变代码执行流程的操作
    - 这些指令用于实现高级语言结构，如“if”和“case”语句，以及各种类型的循环
    - Shader支持两种类型的流控制
      - 静态流控制（Static flow control）是基于统一输入的值的
        - 这意味着代码的流在调用时是恒定的
        - 静态流控制的主要好处是允许在不同的情况下使用相同的着色器（例如，不同数量的光源）
      - 动态流控制（Dynamic flow control）基于不同的输入值。
        - 但动态流控制远比静态流量控制更强大但同时也需更高的开销，特别是在调用shader之间，代码流不规律改变的时候
        - 评估一个shader的性能，是评估其在一段时间内处理顶点或像素的个数
        - 如果流对某些元素选择“if”分支，而对其他元素选择“else”分支，这两个分支必须对所有元素进行评估（并且每个元素的未使用分支将被丢弃）

  - Shader程序可以在程序加载或运行时离线编译
    - 和任何编译器一样，有生成不同输出文件和使用不同优化级别的选项。
    - 一个编译过的Shader作为字符串或者文本来存储，并通过驱动程序传递给GPU
# 顶点着色器 Vertext Shader
  - 它是流水线上的第一个阶段，可选是在GPU还是CPU上实现
    - 而在CPU上实现的话，需将CPU中的输出数据发送到GPU进行光栅化
    - 目前几乎所有的GPU都支持顶点着色
  - 顶点着色器是完全可编程的阶段，是专门处理传入的顶点信息的着色器
  - 顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作
  - 顶点着色器一般不处理附加信息， 顶点着色器提供了修改，创建，或者忽略与每个 多边形顶点 相关的值
      - 例如其颜色，法线，纹理坐标和位置。
  - 顶点着色器程序将顶点从模型空间（ModelSpace）变换到齐次裁剪空间（Homogeneous ClipSpace）
    - 一个顶点着色器至少且必须输出此变换位置

  - 顶点着色阶段之前发生了一些数据操作
    - 比如在DirectX中叫做输入装配（InputAssembler）的阶段
      - 会将一些数据流组织在一起，以形成顶点和基元的集合，发送到管线
      - 在input assembler阶段就可以创建构成物体的triangles（或lines，或points）
        - 本质上是创建带有位置和颜色信息的顶点
        - 可以使用同一个位置数组（并使用一个不同的模型变换矩阵）和一个不同的颜色值数组表示第二个物体
      - 在input assembler阶段还支持执行instancing（同一个物体的多个实例）
        - 这种方法支持通过一次简单的draw call，就可以对同一个物体绘制多次，每次绘制实例包含一些与其他实例不同的数据

  - 顶点着色器本身通用核心虚拟机（Common-Shader Core Virtual  Machine）非常相似
      - 传入的每个顶点由顶点着色器程序处理，然后输出一些在三角形或直线上进行插值后获得的值
      - 顶点着色器既不能创建也不能消除顶点，并且由一个顶点生成的结果不能传递到另一个顶点。
      - 由于每个顶点都被独立处理，所以GPU上的任何数量的着色器处理器都可以并行地应用到传入的顶点流上。

  - 顶点着色器的输出可以以许多不同的方式来使用，通常是用于每个实例三角形的生成和光栅化
      - 然后各个像素片段被发送到像素着色器，以便继续处理
      - 而在ShaderModel 4.0中，数据也可以发送到几何着色器（Geometry Shader）或输出流（Streamed
    Output）或同时发动到像素着色器和几何着色器两者中
# 几何着色器 The Geometry Shader
  - 几何着色器（Geometry Shader）是顶点和片段着色器之间一个可选的着色器
  - 几何着色器的输入是单个对象及对象相关的顶点，而对象通常是网格中的三角形，线段或简单的点
    - 另外，扩展的图元可以由几何着色器定义和处理

  - 几何着色器程序的输入是一个单独的类型：点，线段，三角形
    - 两个最右边的图元，包括与线和三角形对象相邻的顶点也可被使用。

  - 几何着色器可以不产生任何的输出
    - 通过这种方法，可以对一个mesh选择性地进行修改，比如通过编辑顶点，增加新的图元，以及删除其他的图元

  - 几何着色器可以改变新传递进来的图元的拓扑结构，且几何着色器可以接收任何拓扑类型的图元，但是只能输出点、折线（line  strip）和三角形条（triangle strips）

  - 几何着色器需要图元作为输入，在处理过程中他可以将这个图元整个丢弃或者输出一个或更多的图元（也就是说它可以产生比它得到的更多或更少的顶点）。
    - 这个能力被叫做几何增长（growing geometry）
    - 如上所述，几何着色器输出的形式只能是点，折线和三角形条。

  - 当我们未添加几何着色器时，默认的行为是将输入的三角形直接输出。
    - 我们添加了几何着色器之后，可以在几何着色器中修改输出的图形，我们可以输出我们想要输出的任何图形



    图
    3.7.一些几何着色器的应用。左图，使用几何着色器实现元球的等值面曲面细分（metaball
    isosurface
    tessellation）。中图，使用了几何着色器和流输出进行线段细分的分形（fractal
    subdivision of line
    segments）。右图，使用顶点和几何着色器的流输出进行布料模拟。（图片来自NVIDIA SDK
    10的示例）
# 流输出 Stream Output
  - GPU的管线的标准使用方式是发送数据到顶点着色器
    - 然后对所得到的三角形进行光栅化处理，并在像素着色器中处理它们
  - 数据总是通过管线传递，无法访问中间结果
    - 流输出的想法在Shader Model4.0中被引入
    - 在顶点着色器（以及可选的几何着色器中）处理顶点之后，除了将数据发送到光栅化阶段之外
      - 也可以输出到流，也就是一个有序数组中进行处理,除此之外还要发送到rasterization阶
    - 可以完全关掉光栅化，然后管线纯粹作为非图形流处理器来使用  
      - 以这种方式处理的数据可以通过管线回传，从而允许迭代处理
      - 这种操作特别适用于模拟流动的水或其他粒子特效
# 像素着色器 Pixel Shader
  - 像素着色器(PixelShader，Direct3D中的叫法)，常常又称为片断着色器,片元着色器(Fragment Shader,
    OpenGL中的叫法)
    - 用于进行逐像素计算颜色的操作，让复杂的着色方程在每一个像素上执行
    - 像素着色器是光栅化阶段的主要步骤之一
    - 在顶点和几何着色器执行完其操作之后，图元会被裁剪、屏幕映射，结束几何阶段，到达光栅化阶段，在光栅化阶段中先经历三角形设定和三角形遍历，之后来到像素着色阶段

  - 像素着色器常用来处理场景光照和与之相关的效果，如凸凹纹理映射和调色
    - 名称片断着色器似乎更为准确，因为对于着色器的调用和屏幕上像素的显示并非一一对应
    - 举个例子，对于一个像素，片断着色器可能会被调用若干次来决定它最终的颜色，那些被遮挡的物体也会被计算，直到最后的深度缓冲才将各物体前后排序。

  - 像素着色程序通常在最终合并阶段设置片段颜色以进行合并，而深度值也可以由像素着色器修改
    - 模板缓冲（stencil buﬀer ）值是不可修改的，而是将其传递到合并阶段（merge stage）
    - 在SM2.0以及以上版本，像素着色器也可以丢弃（discard）传入的片段数据，即不产生输出
      - 这样的操作会消耗性能，因为通常在这种情况下不能使用由GPU执行的优化
      - 诸如雾计算和alpha测试的操作已经从合并操作转移到SM 4.0中的像素着色器里计算

  - 顶点着色程序的输出，在经历裁剪、屏幕映射、三角形设定、三角形遍历后，实际上变成了像素着色程序的输入
    - 在ShaderModel4.0中，共有16个向量（每个向量含4个值）可以从顶点着色器传到像素着色器
    - 当使用几何着色器时，可以输出32个向量到像素着色器中
  - 像素着色器的追加输入是在ShaderModel3.0中引入的
    - 例如，三角形的哪一面是可见的是通过输入标志来加入的
      - 这个值对于在单个通道中的正面和背面渲染不同材质十分重要
      - 而且像素着色器也可以获得片段的屏幕位置
# 合并阶段 The Merging Stage
  - 作为光栅化阶段名义上的最后一个阶段，合并阶段（The MergingStage）
    - 是将像素着色器中生成的各个片段的深度和颜色与帧缓冲结合在一起的地方。
    - 这个阶段也就是进行模板缓冲（Stencil-Buffer）和Z缓冲（Z-buffer）操作的地方
    - 最常用于透明处理（Transparency）和合成操作（Compositing）的颜色混合（Color
    Blending）操作也是在这个阶段进行的

  - 虽然合并阶段不可编程，但却是高度可配置的
    - 在合并阶段可以设置颜色混合来执行大量不同的操作
    - 最常见的是涉及颜色和Alpha值的乘法，加法，和减法的组合
    - 其他操作也是可能的，比如最大值，最小值以及按位逻辑运算
# 效果 Effect
  - GPU渲染管线中的可编程阶段有顶点、几何和像素着色器三个部分，他们需要相互结合在一起使用
    - 正因如此，不同的团队研发出了不同的特效语言
    - 例如HLSL，FX，CgFX，以及COLLADA FX，来将他们更好的结合在一起
  - 一个效果文件通常会包含所有执行一种特定图形算法的所有相关信息
    - 通常定义一些可被应用程序赋值的全局参数
    - 例如，一个单独的Effectfile可能定义渲染塑料材质需要的vs(顶点着色器)和ps（像素着色器）
    - 它可能暴露一些参数例如塑料颜色和粗糙度，这样渲染每个模型的时候可以改变效果而仅仅使用同一个特效文件
    - 一个效果文件中能存储很多techniques
      - 这些techniques通常是一个相同effect的变体，每种对应于一个不同的Shader
      Model（SM2.0，SM3.0等等）
---
## 图形渲染与视觉外观
- 渲染三维模型的图像时，模型不仅应该具有正确的几何形状，还应该具有期望的视觉外观
- 现实世界中光源和材质交互的方法，通过一个简单的光照和表面模型的示例，讲述如何使用可编程的shaders实现这样的模型示例

- 三种物理现象：
  - 光线从灯光发出并直接传播给房间里其他物体。
  - 物体表面吸收一些物体，并将一些物体散射到新的方向。没有被吸收的光线继续在环境中移动，遇到其他物体。
  - 通过场景的光一小部分光进入用于捕获图像的传感器（如摄像机）
- 所有这三种现象的根据
  - 首先，光是由台灯发出的，并直接传播到房间中的物体上
  - 物体的表面会吸收一部分光线并将一些光线散射到新的方向
  - 没有被物体表面吸收的光线会在环境中继续传播，并照射到其他的物体上
  - 最后，在环境中传播的一小部分光线会进入用于捕获图像的传感器中，在该示例中指数码相机的电子传感器

# 光源
  - 光被不同地模拟为几何光线，电磁波或光子（具有一些波特性的量子粒子）
  - 光都是电磁辐射能-通过空间传播的电磁能
  - 光源发光，而不是散射或吸收光
  - 根据渲染目的,光源可以分为三种不同类型：平行光源、点光源和聚光灯
# 材质
  - 在渲染时，通常使用物体的表面来展现场景。而物体的表面又是通过将材质附加到场景中的模型上来描绘的
  - 每种材质对应于一组 shader 程序，纹理，以及其他属性
  - 这些属性用于模拟光与物体的交互作用。
  - 描述在现实世界中光与物质如何相互作用，然后提供一个简单的材质模型
  - 在渲染中，通过将材质附加到场景中的模型来描绘对象外观。每个材质都和一系列的Shader代码
# 散射与吸收
  - 光与物质相互作用都是两种现象：
    - 散射（scattering）
      - 当光线遇到任何种类的光学不连续性（opticaldiscontinuity）时部分光线向多方面改变方向的现象
      - 可能存在于具有不同光学性质的两种物质分界之处，晶体结构破裂处，密度的变化处等
      - 光的散射（scattering）一般又分为反射（reflection）和透射（transmission）
      - 散射不会改变光量，它只是使其改变方向
    - 吸收（absorption）
      - 发生在物质内部，其会导致一些光转变成另一种能量并消失
      - 吸收会减少光量，但不会影响其方向

  - 镜面反射 /高光
    - 表示在表面反射的光
    - 光从一种介质射到它和另一中介质的分界面时，一部分光返回到这种介质中的现象
  - 漫反射（diffuse）
    - 一部分进入物体内部。这部分光要不被物体吸收（通常转化为热能），要不在物体内部散射，其中一部分会从物体表面散射出来而被重新看到
    - 漫反射的每条光线均遵循反射定律
  - 通常把表面着色公式表示为两个单独的计算项
    - specular term（镜面光计算项）表示被表面反射的光
    - diffuse term（漫反射光计算项）表示经过了透射，吸收和散射处理的光
  - 入射光（Incomingillumination）通过
    - 表面辐照度（irradiance）来度量
      - 辐照度（irradiance）是电磁辐射入射于曲面时每单位面积的功率
  - 出射光（outgoinglight）通过
    - 辐射出射度（exitance）来度量
      - 定义为离开表面一点处的面元的辐射能通量除以该面元面积
    - 辐射出射度 除以 辐照度 可以作为材质的衡量特性
      - 对于不发光的表面，该比率为0到1之间
      - 辐射出射度 和 辐照度 的比率对于不同的光颜色是不同的
        - 所以其表示为RGB矢量或者颜色，也就是我们通常说的表面颜色c
    - 光物质相互作用是线性的，使辐照度加倍将会使 辐射出射度 增加一倍
# 表面粗糙度 smoothness
  - 镜面反射项的方向分布取决于表面粗糙度（smoothness，又译作光滑度）
    - 反射光线对于更平滑的表面更加紧密，并且对于较粗糙的表面更加分散
# 着色与着色方程
  - 着色（Shade）是使用方程式根据材质属性和光源，计算沿着视线v的出射光亮度*Lo*的过程
    - 着色方程具有漫反射和镜面反射分量
# 着色方程的漫反射分量
  - L diff （出射光亮度）=C diff（漫反射color） /3.14* EL（辐照度） cosθi
  - 这种类型的漫反射着色也被叫做兰伯特（Lambertian）着色
    - 兰伯特定律指出，对于理想的漫反射表面，出射光亮度与cosθi成正比。
    - 注意，这种夹紧型cos因子（clamped dot product，可写作max(n·l, 0)，通常称为n点乘l因子）
      - 不是兰伯特表面的特征;
    - 正如我们所见，它一般适用于辐照度（irradiance）的度量。
    - 兰伯特表面的决定性特征是出射光亮度（radiance）和辐照度（irradiance）成正比
# 着色方程
  - 组合漫反射和镜面反射/高光两个项，得到完整的着色方程，总出射光亮度Lo：

# 三种着色处理方法
  - 着色处理是计算光照并由此决定像素颜色的过程，存在3种常见的着色处理方法：
    - 平滑着色（Flatshading）：
      - 简单来讲，就是一个三角面用同一个颜色
      - 如果一个三角面的代表顶点(也许是按在index中的第一个顶点)，恰好被光照成了白色，那么整个面都会是白的

    - 高洛德着色（Gouraudshading）：
      - 每顶点求值后的线性插值结果通常称为高洛德着色
      - 在高洛德着色的实现中，顶点着色器传递世界空间的顶点法线和位置到Shade（）
    (首先确保法线矢量长度为1），然后将结果写入内插值
      - 像素着色器将获取内插值并将其直接写入输出
      - 高洛德着色可以为无光泽表面产生合理的结果，但是对于强高光反射的表面

    - 冯氏着色（Phongshading）：
      - 冯氏着色是对像素求值
      - 在冯氏着色实现中，顶点着色器将世界空间法线和位置写入内插值，此值通过像素着色器传递给Shade()函数
      - 而将Shade()函数返回值写入到输出中
        - 请注意，即使表面法线在顶点着色器中缩放为长度1，插值也可以改变其长度
        - 因此可能需要在像素着色器中再次执行此归一化操作。

  - 注意Phong Shading和Phong LightingModel的区别
    - 前者是考虑如何在三个顶点中填充颜色，而后者表示的是物体被光照产生的效果。

  - 注意冯氏着色可以说是三者中最接近真实的着色效果，当然开销也是最大的
    - 因为高洛德着色是每个顶点(vertex)计算一次光照
    - 冯氏着色是每个片元(fragment)或者说每像素计算一次光照
    - 点的法向量是通过顶点的法向量插值得到的
    - 所以说不会出现高洛德着色也许会遇到的失真问题
# 抗锯齿与常见抗锯齿类型总结
  - 抗锯齿（英语：anti-aliasing，简称AA），也译为边缘柔化、消除混叠、抗图像折叠有损，反走样
    - 它是一种消除显示器输出的画面中图物边缘出现凹凸锯齿的技术
    - 那些凹凸的锯齿通常因为高分辨率的信号以低分辨率表示或无法准确运算出3D图形坐标定位时所导致的图形混叠（aliasing）而产生的，抗锯齿技术能有效地解决这些问题

# 超级采样抗锯齿（SSAA）
  - 超级采样抗锯齿（Super-SamplingAnti-Aliasing）是比较早期的抗锯齿方法，比较消耗资源但简单直接
    - 这种抗锯齿方法先把图像映射到缓存并把它放大，再用超级采样把放大后的图像像素进行采样
    - 一般选取2个或4个邻近像素，把这些采样混合起来后，生成的最终像素，令每个像素拥有邻近像素的特征
    - 像素与像素之间的过渡色彩，就变得近似，令图形的边缘色彩过渡趋于平滑
    - 再把最终像素还原回原来大小的图像，并保存到帧缓存也就是显存中，替代原图像存储起来，最后输出到显示器，显示出一帧画面
    - 这样就等于把一幅模糊的大图，通过细腻化后再缩小成清晰的小图
    - 如果每帧都进行抗锯齿处理，游戏或视频中的所有画面都带有抗锯齿效果。
  - 超级采样抗锯齿中使用的采样法一般有两种：
    -   OGSS，顺序栅格超级采样（Ordered GridSuper-Sampling，简称OGSS），采样时选取2个邻近像素。
    -   RGSS，旋转栅格超级采样（Rotated GridSuper-Sampling，简称RGSS），采样时选取4个邻近像素。

  - 作为概念上最简单的一种超采样方法
    - 全场景抗锯齿（Full-SceneAntialiasing,FSAA）以较高的分辨率对场景进行绘制
      - 然后对相邻的采样样本进行平均，从而生成一幅新的图像。

# 多重采样抗锯齿（MSAA）
  - 多重采样抗锯齿（Multi SamplingAnti-Aliasing，简称MSAA）
    - 是一种特殊的超级采样抗锯齿（SSAA）
    - MSAA首先来自于OpenGL
      - 具体是MSAA只对Z缓存（Z-Buffer）和模板缓存(StencilBuffer)中的数据进行超级采样抗锯齿的处理
    - 可以简单理解为只对多边形的边缘进行抗锯齿处理
      - 这样的话，相比SSAA对画面中所有数据进行处理，MSAA对资源的消耗需求大大减弱，不过在画质上可能稍有不如SSAA。

# 覆盖采样抗锯齿（CSAA）

  - 覆盖采样抗锯齿（Coverage SamplingAnti-Aliasing，简称CSAA）
    - 是NVIDIA在G80及其衍生产品首次推向实用化的AA技术
    - 也是目前NVIDIAGeForce8/9/G200系列独享的AA技术
  - CSAA就是在MSAA基础上更进一步的节省显存使用量及带宽
    - 简单说CSAA就是将边缘多边形里需要取样的子像素坐标覆盖掉
    - 把原像素坐标强制安置在硬件和驱动程序预先算好的坐标中
    - 这就好比取样标准统一的MSAA，能够最高效率的执行边缘取样，效能提升非常的显著。
    - 比方说16xCSAA取样性能下降幅度仅比4xMSAA略高一点，处理效果却几乎和8xMSAA一样。
    - 8xCSAA有着4xMSAA的处理效果，性能消耗却和2xMSAA相同。

# 高分辨率抗锯齿（HRAA）

  - 高分辨率抗锯齿方法(High ResolutionAnti-Aliasing，简称HRAA)，也称Quincunx方法，也出自NVIDIA公司。
  - “Quincunx”意思是5个物体的排列方式，其中4个在正方形角上，第五个在正方形中心，也就是梅花形，很像六边模型上的五点图案模式。
  - 此方法中，采样模式是五点梅花状，其中四个样本在像素单元的角上，最后一个在中心。

# 可编程过滤抗锯齿（CFAA）

  - 可编程过滤抗锯齿（Custom FilterAnti-Aliasing，简称CFAA）技术起源于AMD-ATI的R600家庭
    - 简单地说CFAA就是扩大取样面积的MSAA，比方说之前的MSAA是严格选取物体边缘像素进行缩放的
    - 而CFAA则可以通过驱动和谐灵活地选择对影响锯齿效果较大的像素进行缩放
    - 以较少的性能牺牲换取平滑效果。显卡资源占用也比较小。

# 形态抗锯齿（MLAA）

  - 形态抗锯齿（MorphologicalAnti-Aliasing，简称MLAA）
    - 是AMD推出的完全基于CPU处理的抗锯齿解决方案
    - 与MSAA不同，MLAA将跨越边缘像素的前景和背景色进行混合
      - 用第2种颜色来填充该像素,从而更有效地改进图像边缘的变现效果。

# 快速近似抗锯齿（FXAA）

  - 快速近似抗锯齿(Fast Approximate Anti-Aliasing，简称FXAA)
    - 是传统MSAA(多重采样抗锯齿)效果的一种高性能近似
    - 它是一种单程像素着色器，和MLAA一样运行于目标游戏渲染管线的后期处理阶段，但不像后者那样使用DirectCompute，而只是单纯的后期处理着色器，不依赖于任何GPU计算API
    - 正因为如此，FXAA技术对显卡没有特殊要求，完全兼容NVIDIA、AMD的不同显卡(MLAA仅支持A卡)和DirectX
9.0、DirectX 10、DirectX 11。

# 时间性抗锯齿（TXAA）

  - 时间性抗锯齿（Temporal Anti-Aliasing，简称TXAA）
    - 将MSAA、时间滤波以及后期处理相结合，用于呈现更高的视觉保真度
    - 与CG电影中所采用的技术类似，TXAA集MSAA的强大功能与复杂的解析滤镜于一身，可呈现出更加平滑的图像效果
    - TXAA还能够对帧之间的整个场景进行抖动采样，以减少闪烁情形，闪烁情形在技术上又称作时间性锯齿
    - 目前，TXAA有两种模式：TXAA2X和TXAA 4X
      - TXAA 2X可提供堪比8X MSAA的视觉保真度，然而所需性能却与2XMSAA相类似；
      - TXAA 4X的图像保真度胜过8XMSAA，所需性能仅仅与4X MSAA相当。

# 多帧采样抗锯齿（MFAA）

  - 多帧采样抗锯齿（Multi-Frame Sampled Anti-Aliasing，MFAA）是NVIDIA公司根据MSAA改进出的一种抗锯齿技术
  - 目前仅搭载 Maxwell架构GPU的显卡才能使用
  - 可以将MFAA理解为MSAA的优化版，能够在得到几乎相同效果的同时提升性能上的表现
  - MFAA与MSAA最大的差别就在于在同样开启4倍效果的时候MSAA是真正的针对每个边缘像素周围的4个像素进行采样
    - MFAA则是仅仅只是采用交错的方式采样边缘某个像素周围的两个像素


# 透明渲染

  - 透明渲染是是图形学里面的常见问题之一，可以从《Real-Time Rendering3rd》中总结出如下两个算法：

    -   Screen-Door
    Transparency方法。基本思想是用棋盘格填充模式来绘制透明多边形，也就是说，以每隔一个像素绘制一点方式的来绘制一个多边形，这样会使在其后面的物体部分可见，通常情况下，屏幕上的像素比较紧凑，以至于棋盘格的这种绘制方式并不会露馅。同样的想法也用于剪切纹理的抗锯齿边缘，但是在子像素级别中的，这是一种称为alpha覆盖（alpha
    to coverage）的特征。screen-door
    transparency方法的优点就是简单，可以在任何时间任何顺序绘制透明物体，并不需要特殊的硬件支持（只要支持填充模式）。缺点是透明度效果仅在50%时最好，且屏幕的每个区域中只能绘制一个透明物体。

    -   Alpha混合（Alpha
    Blending）方法。这个方法比较常见，其实就是按照Alpha混合向量的值来混合源像素和目标像素。当在屏幕上绘制某个物体时，与每个像素相关联的值有RGB颜色和Z缓冲深度值，以及另外一个成分alpha分量，这个alpha值也可以根据需要生成并存储，它描述的是给定像素的对象片段的不透明度的值。
    alpha为1.0表示对象不透明，完全覆盖像素所在区域;
    0.0表示像素完全透明。为了使对象透明，在现有场景的上方，以小于1的透明度进行绘制即可。每个像素将从渲染管线接收到一个RGBA结果，并将这个值和原始像素颜色相混合。


# 透明排序
  - 要将透明对象正确地渲染到场景中，通常需要对物体进行排序
    - 下面分别介绍两种比较基本的透明排序方法（深度缓存和油画家算法）和两种高级别的透明排序算法（加权平均值算法和深度剥离）

# 深度缓存（Z-Buffer）
  - Z-Buffer也称深度缓冲
    - 在计算机图形学中，深度缓冲是在三维图形中处理图像深度坐标的过程，这个过程通常在硬件中完成，它也可以在软件中完成，它是可见性问题的一个解决方法
    - 可见性问题是确定渲染场景中哪部分可见、哪部分不可见的问题。

  - Z-buffer的限制是每像素只存储一个对象
    - 如果一些透明对象与同一个像素重叠，那么单独的Z-buffer就不能存储并且稍后再解析出所有可见对象的效果
    - 这个问题是通过改变加速器架构来解决的，比如用A-buffer。A-buffer具有“深度像素（deeppixels）”
      - 其可以在单个像素中存储一系列呈现在所有对象之后被解析为单个像素颜色的多个片段
      - 但需注意，Z-buffer是市场的主流选择

# 画家算法（Painter's Algorithm）

画家算法也称优先填充算法，效率虽然较低，但还是可以有效处理透明排序的问题。其基本思想是按照画家在绘制一幅画作时，首先绘制距离较远的场景，然后用绘制距离较近的场景覆盖较远的部分的思想。画家算法首先将场景中的多边形根据深度进行排序，然后按照顺序进行描绘。这种方法通常会将不可见的部分覆盖，这样就可以解决可见性问题。

# 加权平均值算法（Weighted Average）

使用简单的透明混合公式来实现无序透明渲染的算法，它通过扩展透明混合公式，来实现无序透明物件的渲染，从而得到一定程度上逼真的结果。

# 深度剥离算法（Depth Peeling）

深度剥离是一种对深度值进行排序的技术。它的原理比较直观，标准的深度检测使场景中的Z值最小的点输出到屏幕上，就是离我们最近的顶点。但还有离我们第二近的顶点，第三近的顶点存在。要想显示它们，可以用多遍渲染的方法。第一遍渲染时，按照正常方式处理，这样就得到了离我们最近的表面中的每个顶点的z值。在第二遍渲染时，把现在每个顶点的深度值和刚才的那个深度值进行比较，凡是小于等于第一遍得到的z值，把它们剥离，后面的过程依次类推即可。


每个深度剥离通道渲染特定的一层透明通道。左侧是第一个Pass，直接显示眼睛可见的层，中间的图显示了第二层，显示了每个像素处第二靠近透明表面的像素。右边的图是第三层，每个像素处第三靠近透明表面的像素。



# 伽玛校正

  - 伽马校正（Gamma correction） 又叫伽马非线性化（gammanonlinearity），伽马编码（gamma encoding）
或直接叫伽马（gamma）
  - 是用来对光线的辐照度（luminance）或是三色刺激值（tristimulusvalues）所进行非线性的运算或反运算的一种操作
  - 为图像进行伽马编码的目的是用来对人类视觉的特性进行补偿，从而根据人类对光线或者黑白的感知，最大化地利用表示黑白的数据位或带宽

## 纹理贴图及相关技术
-
# 高级着色：BRDF及相关技术
  -
# 延迟渲染
  -
#  全局光照:光线追踪、路径追踪与GI
  -

# 基于图像的渲染技术总结
# 非真实感渲染(NPR)
# 渲染加速算法
# 渲染管线优化方法
